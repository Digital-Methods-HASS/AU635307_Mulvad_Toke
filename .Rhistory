coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == -3)
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
get_sentiments("afinn", language = danish)
get_sentiments("afinn", language = "danish"")
get_sentiments("afinn")
docs_afinn <- docs_stop %>%
inner_join(get_sentiments("afinn"))
sentiments_afinn
sentiment_afinn
??afinn
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
pdf_combine(c("texts/AarVrids_1861_1865.pdf", "texts/AarVrids_1866_1870.pdf", "texts/AarVrids_1871_1875.pdf", "texts/AarVrids_1876_1880.pdf", "texts/AarVrids_1881_1891.pdf"), "joined_texts1.pdf")
pdf_combine(c("texts/AarVrids_1892_1899.pdf", "texts/AarVrids_1900_1910.pdf", "texts/AarVrids_1911_1913.pdf", "texts/AarVrids_1913_1924.pdf", "texts/AarVrids_1924_1950.pdf"), "joined_texts2.pdf")
pdf_combine(c("joined_texts1.pdf", "joined_texts2.pdf"), "textcorpus.pdf")
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
docs_path <- here("texts","textcorpus.pdf")
docs_corpus <- pdf_text(docs_path)
docs_df <- data.frame(docs_corpus) %>%
mutate(text_full = str_split(docs_corpus, pattern = '\\n')) %>%
unnest(text_full) %>%
mutate(text_full = str_trim(text_full))
docs_tokens <- docs_df %>%
unnest_tokens(word, text_full)
# See how this differs from `docs_df`
# Each word has its own row!
docs_wc <- docs_tokens %>%
count(word) %>%
arrange(-n)
docs_stop <- docs_tokens %>%
anti_join(stop_words) %>%
select(-docs_corpus)
docs_swc <- docs_stop %>%
count(word) %>%
arrange(-n)
# This code will filter out numbers by asking:
# If you convert to as.numeric, is it NA (meaning those words)?
# If it IS NA (is.na), then keep it (so all words are kept)
# Anything that is converted to a number is removed
docs_no_numeric <- docs_stop %>%
filter(is.na(as.numeric(word)))
# There are almost 13556 unique words
length(unique(docs_no_numeric$word))
# We probably don't want to include them all in a word cloud. Let's filter to only include the top 100 most frequent?
docs_top100 <- docs_no_numeric %>%
count(word) %>%
arrange(-n) %>%
head(100)
docs_afinn <- docs_stop %>%
inner_join(get_sentiments("afinn"))
docs_afinn_hist <- docs_afinn %>%
count(value)
# Plot them:
ggplot(data = docs_afinn_hist, aes(x = value, y = n)) +
geom_col()
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == 2)
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
docs_summary <- docs_afinn %>%
summarize(
mean_score = mean(value),
median_score = median(value)
)
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == -5)
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == 1)
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == -1)
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
lexicon_afinn()
lexicon_afinn()
lexicon_afinn("danish")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
get_sentiments("afinn")
afinn = language("danish")
get_sentiments("afinn")
docs_afinn <- docs_stop %>%
inner_join(get_sentiments("afinn"))
docs_afinn_hist <- docs_afinn %>%
count(value)
# Plot them:
ggplot(data = docs_afinn_hist, aes(x = value, y = n)) +
geom_col()
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == 2 )
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
docs_summary <- docs_afinn %>%
summarize(
mean_score = mean(value),
median_score = median(value)
)
install.packages("devtools")
install.packages("Rtools")
devtools::install_github("Guscode/Sentida")
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
devtools::install_github("Guscode/Sentida")
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
devtools::install_github("Guscode/Sentida")
force = TRUE
install.packages("devtools")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
devtools::install_github("Guscode/Sentida")
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
library(Sentida)
sentida("textcorpus.pdf", output = "total")
sentida("textcorpus.pdf", output = "mean")
install.packages("pdftables")
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
library(Sentida)
library(pdftables)
convert_pdf("test_texts.pdf", "test_text.csv")
sentida("textcorpus.pdf", output = "mean")
knitr::opts_chunk$set(echo = TRUE)
text_p106 <- pdf_text[106]
text_p106 <- docs_corpus[106]
text_p106
docs_tokens <- docs_df %>%
unnest_tokens(word, text_full)
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
docs_tokens <- docs_df %>%
unnest_tokens(word, text_full)
# See how this differs from `docs_df`
# Each word has its own row!
docs_stop <- docs_tokens %>%
anti_join(stop_words(kind = "da")) %>%
select(-docs_corpus)
docs_stop <- docs_tokens %>%
anti_join(stop_words(kind = "danish")) %>%
select(-docs_corpus)
docs_stop <- docs_tokens %>%
anti_join(stop_words("danish")) %>%
select(-docs_corpus)
docs_stop <- docs_tokens %>%
anti_join(stop_words("da")) %>%
select(-docs_corpus)
docs_stop <- docs_tokens %>%
anti_join(stop_words) %>%
select(-docs_corpus)
docs_swc <- docs_stop %>%
count(word) %>%
arrange(-n)
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
docs_stop <- docs_tokens %>%
anti_join(stopwords("da")) %>%
select(-docs_corpus)
docs_stop <- docs_tokens %>%
anti_join(stop_words) %>%
select(-docs_corpus)
docs_stop <- docs_tokens %>%
anti_join(stopwords) %>%
select(-docs_corpus)
docs_stop <- docs_tokens %>%
anti_join(stop_words) %>%
select(-docs_corpus)
# There are almost 13556 unique words
length(unique(docs_no_numeric$word))
# We probably don't want to include them all in a word cloud. Let's filter to only include the top 100 most frequent?
docs_top100 <- docs_no_numeric %>%
count(word) %>%
arrange(-n) %>%
head(100)
docs_wc <- docs_tokens %>%
count(word) %>%
arrange(-n)
get_sentiments("afinn")
afinn_pos
afinn_pos <- get_sentiments("afinn") %>%
filter(value %in% c(3,4,5))
afinn_pos
docs_afinn_hist <- docs_afinn %>%
count(value)
# Plot them:
ggplot(data = docs_afinn_hist, aes(x = value, y = n)) +
geom_col()
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == 2 )
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == 3 )
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == 4 )
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == 1 )
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == -1 )
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == -2 )
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == -3 )
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == -4 )
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == -5 )
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
# What are these '2' words?
docs_afinn2 <- docs_afinn %>%
filter(value == 5 )
# Check the unique 2-score words:
unique(docs_afinn2$word)
# Count & plot them
docs_afinn2_n <- docs_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = docs_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# OK so what's the deal with confidence? And is it really "positive" in the emotion sense?
knitr::opts_chunk$set(echo = TRUE)
docs_afinn_hist <- docs_afinn %>%
count(value)
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
docs_afinn_hist <- docs_afinn %>%
count(value)
ggplot(data = docs_afinn_hist, aes(x = value, y = number of words)) +
docs_afinn_hist <- docs_afinn %>%
count(value)
ggplot(data = docs_afinn_hist, aes(x = value, y = n)) +
geom_col()
docs_afinn_hist <- docs_afinn %>%
count(value)
ggplot(data = docs_afinn_hist, aes(x = value, y = n)) +
geom_col(mapping = aes(x = "Semantic Rating", y = "number of words"))
docs_afinn_hist <- docs_afinn %>%
count(value)
ggplot(data = docs_afinn_hist, aes(x = value, y = n)) +
geom_col()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
docs_path <- here("texts","textcorpus.pdf")
docs_corpus <- pdf_text(docs_path)
docs_path <- here("texts","textcorpus.pdf")
docs_corpus <- pdf_text(docs_path)
docs_path <- here("texts","textcorpus.pdf")
docs_corpus <- pdf_text(docs_path)
docs_path <- here("texts","textcorpus.pdf")
docs_corpus <- pdf_text(docs_path)
text_p106 <- docs_corpus[106]
text_p106
docs_df <- data.frame(docs_corpus) %>%
mutate(text_full = str_split(docs_corpus, pattern = '\\n')) %>%
unnest(text_full) %>%
mutate(text_full = str_trim(text_full))
docs_tokens <- docs_df %>%
unnest_tokens(word, text_full)
#Which give a table of 1.066.629 columns
docs_wc <- docs_tokens %>%
count(word) %>%
arrange(-n)
#Adds up to 61.035 words
docs_stop <- docs_tokens %>%
anti_join(stop_words) %>%
select(-docs_corpus)
docs_swc <- docs_stop %>%
count(word) %>%
arrange(-n)
#Without stopwords there are 906.932 columns
docs_no_numeric <- docs_stop %>%
filter(is.na(as.numeric(word)))
#After removing numbers there are 773.579 columns left
length(unique(docs_no_numeric$word))
#And so, there are 56695 unique words in the corpus
get_sentiments("afinn")
docs_afinn <- docs_stop %>%
inner_join(get_sentiments("afinn"))
docs_afinn_hist <- docs_afinn %>%
count(value)
ggplot(data = docs_afinn_hist, aes(x = value, y = n)) +
geom_col()
docs_summary <- docs_afinn %>%
summarize(
mean_score = mean(value),
median_score = median(value)
)
#The mean for the corpus is just on the positive site of the ranking system (0.35) and the median score is also near the middle but nonetheless positive (+1)
library(tidyverse)
library(pdftools)
library(tidytext)
library(textdata)
library(here)
