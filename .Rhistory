docs <- textclean(docs)
cleantext <- function(VCorpus){
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, removeWords, c("syllogism", "tautology"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, stripWhitespace)
#docs <- tm_map(docs, PlainTextDocument)
docs
}
docs <- cleantext(docs)
dtm <- DocumentTermMatrix(docs)
cleantext <- function(VCorpus){
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, removeWords, c("syllogism", "tautology"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, stripWhitespace)
#docs <- tm_map(docs, PlainTextDocument)
docs
}
docs <- textclean(docs)
cleantext <- function(VCorpus){
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, removeWords, c("syllogism", "tautology"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, stripWhitespace)
#docs <- tm_map(docs, PlainTextDocument)
docs
}
docs <- cleantext(docs)
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, removeWords, c("syllogism", "tautology"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, stripWhitespace)
#docs <- tm_map(docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, removeWords, c("syllogism", "tautology"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, removeWords, c("syllogism", "tautology"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, stripWhitespace)
#docs <- tm_map(docs, PlainTextDocument)
inspect(docs[1:5, 1:20]) # view first 5 docs & first 20 terms - modify as you like
dim(docs) #This will display the number of documents & terms (in that order)
dtm <- DocumentTermMatrix(docs)
dtm <- DocumentTermMatrix(docs)
dtm <- DocumentTermMatrix(docs)
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, removeWords, c("syllogism", "tautology"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
library(tidyverse)
library(tm)
library(tidytext)
library(NLP)
knitr::opts_chunk$set(echo = TRUE)
cname <- file.path("./", "data")
cname
dir(cname)
library(tm)
docs <- VCorpus(DirSource(cname))
for (j in seq(docs)) {
docs[[j]] <- gsub( "â\200\231","", docs[[j]]) # remove apostrophe
docs[[j]] <- gsub( "â\200","-", docs[[j]])  # reinsert hyphen
docs[[j]] <- gsub("@"," ", docs[[j]])
docs[[j]] <- gsub("\\|", " ", docs[[j]])
docs[[j]] <- gsub("\u2028", " ", docs[[j]])
docs[[j]] <- gsub("/"," ", docs[[j]])
}
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, removeWords, c("syllogism", "tautology"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
tdm <- TermDocumentMatrix(docs)   # this is a transposed document term matrix
inspect(docs[1:5, 1:20]) # view first 5 docs & first 20 terms - modify as you like
inspect(dtm[1:5, 1:20]) # view first 5 docs & first 20 terms - modify as you like
inspect(dtm) # view first 5 docs & first 20 terms - modify as you like
inspect(dtm, docs) # view first 5 docs & first 20 terms - modify as you like
inspect(dtm) # view first 5 docs & first 20 terms - modify as you like
inspect(dtm) # view first 5 docs & first 20 terms - modify as you like
dim(dtm) #This will display the number of documents & terms (in that order)
#install.packages("textclean")
??dim
docs_sentiment <- docs %>%
inner_join(get_sentiments("bing"), by = c(term = "word"))
if(!require("devtools")) install.packages("devtools")
devtools::install_github("Guscode/Sentida")
library(Sentida)
library(devtools)
library(usethis)
if(!require("devtools")) install.packages("devtools")
devtools::install_github("Guscode/Sentida")
library(Sentida)
install.packages(Rtools)
/c/Users/Toke J. Mulvad/OneDrive/Skrivebord/DigitalToolbox="${RTOOLS40_HOME}\usr\bin;${/c/Users/Toke J. Mulvad/OneDrive/Skrivebord/DigitalToolbox}"
PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"
writeLines('PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"', con = "~/.Renviron")
writeLines('C:/Users/Toke J. Mulvad/OneDrive/Skrivebord/DigitalToolbox="${RTOOLS40_HOME}\usr\bin;${C:/Users/Toke J. Mulvad/OneDrive/Skrivebord/DigitalToolbox}"', con = "~/.Renviron")
knitr::opts_chunk$set(echo = TRUE)
get_sentiment(char_v, method = "syuzhet", path_to_tagger = NULL,
cl = NULL, language = "english", lexicon = NULL)
get_sentiment(docs, method = "syuzhet", path_to_tagger = NULL,
cl = NULL, language = "danish", lexicon = NULL)
get_sentiment(docs, method = "nrc", path_to_tagger = NULL,
cl = NULL, language = "danish", lexicon = "word")
??get_sentiment
library(nrc)
library(tidyverse)
library(tm)
library(tidytext)
library(NLP)
knitr::opts_chunk$set(echo = TRUE)
cname <- file.path("./", "text")
cname
dir(cname)
docs <- VCorpus(DirSource(cname))
writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub( "â\200\231","", docs[[j]]) # remove apostrophe
docs[[j]] <- gsub( "â\200","-", docs[[j]])  # reinsert hyphen
docs[[j]] <- gsub("@"," ", docs[[j]])
docs[[j]] <- gsub("\\|", " ", docs[[j]])
docs[[j]] <- gsub("\u2028", " ", docs[[j]])
docs[[j]] <- gsub("/"," ", docs[[j]])
}
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, removeWords, c("syllogism", "tautology"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
writeLines(as.character(docs[1]))
dtm <- DocumentTermMatrix(docs)
tdm <- TermDocumentMatrix(docs)   # this is a transposed document term matrix
inspect(dtm) # view first 5 docs & first 20 terms - modify as you like
inspect(dtm[1:5]) # view first 5 docs & first 20 terms - modify as you like
inspect(dtm(1:5)) # view first 5 docs & first 20 terms - modify as you like
inspect(dtm) # view first 5 docs & first 20 terms - modify as you like
inspect(dtm[1:6, 1:6]) # view first 5 docs & first 20 terms - modify as you like
library(tidyverse)
library(tm)
library(tidytext)
library(SnowballC)
library(NLP)
inspect(dtm[1:6, 1:6]) # view first 5 docs & first 20 terms - modify as you like
library(tidyverse)
library(NLP)
library(tm)
library(tidytext)
library(SnowballC)
library(RColorBrewer)
inspect(dtm[1:6, 1:6]) # view first 5 docs & first 20 terms - modify as you like
library(corpus)
library(tidyverse)
library(NLP)
library(tm)
library(tidytext)
library(SnowballC)
library(RColorBrewer)
knitr::opts_chunk$set(echo = TRUE)
cname <- file.path("./", "text")
cname
dir(cname)
docs <- VCorpus(DirSource(cname))
writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub( "â\200\231","", docs[[j]]) # remove apostrophe
docs[[j]] <- gsub( "â\200","-", docs[[j]])  # reinsert hyphen
docs[[j]] <- gsub("@"," ", docs[[j]])
docs[[j]] <- gsub("\\|", " ", docs[[j]])
docs[[j]] <- gsub("\u2028", " ", docs[[j]])
docs[[j]] <- gsub("/"," ", docs[[j]])
}
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, removeWords, c("syllogism", "tautology"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
writeLines(as.character(docs[1]))
dtm <- DocumentTermMatrix(docs)
tdm <- TermDocumentMatrix(docs)   # this is a transposed document term matrix
inspect(dtm[1:6, 1:6]) # view first 5 docs & first 20 terms - modify as you like
writeLines(as.character(docs[1, [1:20]]))
writeLines(as.character(docs[1[1:20]]))
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, removeWords, c("syllogism", "tautology"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, stripWhitespace)
#docs <- tm_map(docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
tdm <- TermDocumentMatrix(docs)   # this is a transposed document term matrix
inspect(dtm[1:6, 1:6]) # view first 5 docs & first 20 terms - modify as you like
inspect(dtm) # view first 5 docs & first 20 terms - modify as you like
docs <- tm_map(docs, removeWords, stopwords("danish"))
#docs <- tm_map(docs, removeWords, c("syllogism", "tautology"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, stripWhitespace)
#docs <- tm_map(docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
tdm <- TermDocumentMatrix(docs)   # this is a transposed document term matrix
inspect(dtm) # view first 5 docs & first 20 terms - modify as you like
inspect(dtm) # view first 5 docs & first 20 terms - modify as you like
inspect(docs) # view first 5 docs & first 20 terms - modify as you like
dim(dtm) #This will display the number of documents & terms (in that order)
inspect(tdm) # view first 5 docs & first 20 terms - modify as you like
inspect(dtm) # view first 5 docs & first 20 terms - modify as you like
inspect(tdm) # view first 5 docs & first 20 terms - modify as you like
inspect(dtm) # view first 5 docs & first 20 terms - modify as you like
writeLines(as.character(docs[1))
writeLines(as.character(docs[1]))
get_sentiments("nrc")
library(textdata)
install.packages(textdata)
library(fs)
library(readr)
library(tibble)
library(rappdirs)
install.packages("rappdirs")
install.packages("textdata")
library(textdata)
get_sentiments("nrc")
knitr::opts_chunk$set(echo = TRUE)
inspect(dtm) # view first 5 docs & first 20 terms - modify as you like
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(NLP)
library(tm)
library(tidytext)
library(SnowballC)
library(RColorBrewer)
cname <- file.path("./", "text")
cname
dir(cname)
docs <- VCorpus(DirSource(cname))
writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub( "â\200\231","", docs[[j]]) # remove apostrophe
docs[[j]] <- gsub( "â\200","-", docs[[j]])  # reinsert hyphen
docs[[j]] <- gsub("@"," ", docs[[j]])
docs[[j]] <- gsub("\\|", " ", docs[[j]])
docs[[j]] <- gsub("\u2028", " ", docs[[j]])
docs[[j]] <- gsub("/"," ", docs[[j]])
}
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
#docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, stripWhitespace)
writeLines(as.character(docs[1]))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
tdm <- TermDocumentMatrix(docs)   # this is a transposed document term matrix
inspect(dtm) # view first 5 docs & first 20 terms - modify as you like
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, stripWhitespace)
#docs <- tm_map(docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
tdm <- TermDocumentMatrix(docs)   # this is a transposed document term matrix
inspect(dtm [1:1, 1:20]) # view first 5 docs & first 20 terms - modify as you like
dim(dtm) #This will display the number of documents & terms (in that order)
inspect(dtm [2:3, 1:20]) # view first 5 docs & first 20 terms - modify as you like
dim(dtm) #This will display the number of documents & terms (in that order)
inspect(dtm [2:3, 50:70]) # view first 5 docs & first 20 terms - modify as you like
dim(dtm) #This will display the number of documents & terms (in that order)
get_sentiments("nrc")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(NLP)
library(tm)
library(tidytext)
library(SnowballC)
library(RColorBrewer)
library(syuzhet)
library(pander)
library(tidyverse)
library(NLP)
library(tm)
library(tidytext)
library(SnowballC)
library(RColorBrewer)
library(syuzhet)
library(pander)
cname <- file.path("./", "text")
cname
dir(cname)
docs <- VCorpus(DirSource(cname))
for (j in seq(docs)) {
docs[[j]] <- gsub( "â\200\231","", docs[[j]]) # remove apostrophe
docs[[j]] <- gsub( "â\200","-", docs[[j]])  # reinsert hyphen
docs[[j]] <- gsub("@"," ", docs[[j]])
docs[[j]] <- gsub("\\|", " ", docs[[j]])
docs[[j]] <- gsub("\u2028", " ", docs[[j]])
docs[[j]] <- gsub("/"," ", docs[[j]])
}
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
tdm <- TermDocumentMatrix(docs)   # this is a transposed document term matrix
pander::pandoc.table([, 1:8], split.table = Inf)
pander::pandoc.table(docs[, 1:8], split.table = Inf)
pander::pandoc.table(docs[1:10, 1:8], split.table = Inf)
pander::pandoc.table(docs[1:10, ], split.table = Inf)
pander::pandoc.table(docs[1:10,], split.table = Inf)
pander::pandoc.table(docs, split.table = Inf)
pander::pandoc.table(dtm, split.table = Inf)
pander::pandoc.table(docs, split.table = Inf)
class(docs)
class(cname)
pander::pandoc.table(cname, split.table = Inf)
class(dtm)
class(text)
class(docs)
class(VCorpus)
class(Corpus)
class(j)
text %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
count(word, sort = TRUE)
docs %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
count(word, sort = TRUE)
textdata <- as_tibble(readtext("./data/*.txt",
docvarsfrom = "filenames",
docvarnames = c("AarsVrids", "[0-9]+", "[0-9]+"),
dvsep = "_",
encoding = "UTF-8"))
library(tidyverse)
library(NLP)
library(tm)
library(tidytext)
library(SnowballC)
library(RColorBrewer)
library(syuzhet)
library(pander)
textdata <- as_tibble(readtext("./data/*.txt",
docvarsfrom = "filenames",
docvarnames = c("AarsVrids", "[0-9]+", "[0-9]+"),
dvsep = "_",
encoding = "UTF-8"))
library(tidyverse)
library(NLP)
library(tm)
library(tidytext)
library(SnowballC)
library(RColorBrewer)
library(syuzhet)
library(pander)
library(readtext)
library(tidyverse)
library(NLP)
library(tm)
library(tidytext)
library(SnowballC)
library(RColorBrewer)
library(syuzhet)
library(pander)
library(readtext)
textdata <- as_tibble(readtext("./data/*.txt",
docvarsfrom = "filenames",
docvarnames = c("AarsVrids", "[0-9]+", "[0-9]+"),
dvsep = "_",
encoding = "UTF-8"))
textdata <- as_tibble(readtext("./text/*.txt",
docvarsfrom = "filenames",
docvarnames = c("AarsVrids", "[0-9]+", "[0-9]+"),
dvsep = "_",
encoding = "UTF-8"))
%>%
textdata %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
count(word, sort = TRUE)
textdata <- tm_map(textdata, removePunctuation)
#textdata <- tm_map(textdata, removePunctuation)
textdata <- tm_map(textdata, removeNumbers)
library(tidyverse)
library(NLP)
library(tm)
library(tidytext)
library(SnowballC)
library(RColorBrewer)
library(syuzhet)
library(pander)
library(readtext)
textdata <- tm_map(textdata, removePunctuation)
textdata <- as_tibble(readtext("./text/*.txt",
docvarsfrom = "filenames",
docvarnames = c("AarsVrids", "[0-9]+", "[0-9]+"),
dvsep = "_",
encoding = "UTF-8"))
textdata <- tm_map(textdata, removePunctuation)
textdata_clean <- textdata %>%
mutate(text =
str_replace_all(
text,
pattern =
"\\d", ""))
textdata_clean %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
count(word, sort = TRUE)
#textdata <- tm_map(textdata, removePunctuation)
#textdata <- tm_map(textdata, removeNumbers)
#textdata <- tm_map(textdata, tolower)
#textdata <- tm_map(textdata, removeWords, stopwords("danish"))
#textdata <- tm_map(textdata, stripWhitespace)
#textdata <- tm_map(textdata, PlainTextDocument)
get_sentiment(textdata_clean, method = "nrc", path_to_tagger = NULL,
cl = NULL, language = "danish", lexicon = "word")
pander::pandoc.table(textdata_clean, split.table = Inf)
View(textdata)
View(textdata_clean)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(NLP)
library(tm)
library(tidytext)
library(SnowballC)
library(RColorBrewer)
library(syuzhet)
library(pander)
library(readtext)
library(tidyverse)
library(NLP)
library(tm)
library(tidytext)
library(SnowballC)
library(RColorBrewer)
library(syuzhet)
library(pander)
library(readtext)
cname <- file.path("./", "text")
cname
dir(cname)
docs <- VCorpus(DirSource(cname))
for (j in seq(docs)) {
docs[[j]] <- gsub( "â\200\231","", docs[[j]]) # remove apostrophe
docs[[j]] <- gsub( "â\200","-", docs[[j]])  # reinsert hyphen
docs[[j]] <- gsub("@"," ", docs[[j]])
docs[[j]] <- gsub("\\|", " ", docs[[j]])
docs[[j]] <- gsub("\u2028", " ", docs[[j]])
docs[[j]] <- gsub("/"," ", docs[[j]])
}
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, stopwords("danish"))
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
tdm <- TermDocumentMatrix(docs)   # this is a transposed document term matrix
inspect(dtm [2:3, 50:70])
dim(dtm) #This will display the number of documents & terms (in that order)
get_sentiments("nrc")
